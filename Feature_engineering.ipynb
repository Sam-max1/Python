{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering in Python for Data Science\n",
    "\n",
    "Feature engineering is the process of creating new features or transforming existing ones to improve model performance. Here's a comprehensive guide with examples:\n",
    "\n",
    "### 1. Basic Feature Transformations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Create sample dataset\n",
    "data = {\n",
    "    'age': [25, 35, 45, 55, 65],\n",
    "    'income': [30000, 45000, 55000, 80000, 100000],\n",
    "    'education': ['High School', 'Bachelors', 'Masters', 'PhD', 'Bachelors'],\n",
    "    'purchase_date': pd.date_range(start='2023-01-01', periods=5)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Numerical Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "df['age_scaled'] = scaler.fit_transform(df[['age']])\n",
    "df['income_scaled'] = scaler.fit_transform(df[['income']])\n",
    "\n",
    "# Categorical Encoding\n",
    "le = LabelEncoder()\n",
    "df['education_encoded'] = le.fit_transform(df['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Date-based Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract various date components\n",
    "df['purchase_year'] = df['purchase_date'].dt.year\n",
    "df['purchase_month'] = df['purchase_date'].dt.month\n",
    "df['purchase_day'] = df['purchase_date'].dt.day\n",
    "df['purchase_dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "df['purchase_quarter'] = df['purchase_date'].dt.quarter\n",
    "\n",
    "# Create seasonal features\n",
    "df['is_weekend'] = df['purchase_dayofweek'].isin([5, 6]).astype(int)\n",
    "df['is_month_end'] = df['purchase_date'].dt.is_month_end.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Binning and Discretization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal-width binning\n",
    "df['age_bins'] = pd.cut(df['age'], \n",
    "                       bins=3, \n",
    "                       labels=['Young', 'Middle', 'Senior'])\n",
    "\n",
    "# Equal-frequency binning (quantiles)\n",
    "df['income_quartiles'] = pd.qcut(df['income'], \n",
    "                                q=4, \n",
    "                                labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n",
    "\n",
    "# Custom binning\n",
    "custom_bins = [0, 30000, 60000, 100000, float('inf')]\n",
    "custom_labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "df['income_custom_bins'] = pd.cut(df['income'], \n",
    "                                 bins=custom_bins, \n",
    "                                 labels=custom_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. Interaction Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating interaction features\n",
    "df['age_income_interaction'] = df['age'] * df['income']\n",
    "df['age_income_ratio'] = df['age'] / df['income']\n",
    "\n",
    "# Polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(df[['age', 'income']])\n",
    "poly_features_df = pd.DataFrame(poly_features, \n",
    "                              columns=['age', 'income', 'age²', 'age*income', 'income²'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 5. Text Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample text data\n",
    "texts = [\n",
    "    \"This is a good product\",\n",
    "    \"The service was terrible\",\n",
    "    \"Amazing experience overall\"\n",
    "]\n",
    "\n",
    "# Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(texts)\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), \n",
    "                     columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(texts)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n",
    "                       columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 6. Advanced Feature Engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation features\n",
    "def create_agg_features(df, group_col, agg_col):\n",
    "    \"\"\"Create aggregation features for a given column\"\"\"\n",
    "    agg_funcs = ['mean', 'min', 'max', 'std']\n",
    "    \n",
    "    agg_features = df.groupby(group_col)[agg_col].agg(agg_funcs)\n",
    "    agg_features.columns = [f'{agg_col}_{func}' for func in agg_funcs]\n",
    "    \n",
    "    return agg_features.reset_index()\n",
    "\n",
    "# Time-based features\n",
    "def create_time_features(df, date_col):\n",
    "    \"\"\"Create time-based features from a date column\"\"\"\n",
    "    df[f'{date_col}_hour'] = df[date_col].dt.hour\n",
    "    df[f'{date_col}_minute'] = df[date_col].dt.minute\n",
    "    df[f'{date_col}_is_business_hour'] = df[date_col].dt.hour.between(9, 17).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 7. Feature Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select top k features based on ANOVA F-value\n",
    "def select_features(X, y, k=5):\n",
    "    \"\"\"Select top k features using ANOVA F-value\"\"\"\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X.columns[selector.get_support()].tolist()\n",
    "    \n",
    "    return X_selected, selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Key Points to Remember:\n",
    "\n",
    "1. **Feature Types**\n",
    "- Numerical features need scaling\n",
    "- Categorical features need encoding\n",
    "- Date features can be decomposed\n",
    "- Text features need vectorization\n",
    "\n",
    "2. **Best Practices**\n",
    "- Always scale features before modeling\n",
    "- Handle missing values appropriately\n",
    "- Document feature engineering steps\n",
    "- Validate new features' importance\n",
    "\n",
    "3. **Common Techniques**\n",
    "- Scaling and normalization\n",
    "- Binning and discretization\n",
    "- Feature interactions\n",
    "- Polynomial features\n",
    "- Aggregations\n",
    "- Time-based features\n",
    "\n",
    "4. **Saving Engineered Features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "df.to_csv('engineered_features.csv', index=False)\n",
    "\n",
    "# Save feature engineering pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    # Add more steps as needed\n",
    "])\n",
    "\n",
    "dump(pipeline, 'feature_engineering_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This comprehensive approach to feature engineering helps prepare your data for machine learning models and can significantly improve model performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
