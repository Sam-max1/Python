{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python in Data Science\n",
    "\n",
    "Python is widely used in data science due to its rich ecosystem of libraries and tools. Here are the main aspects of using Python for data science:\n",
    "\n",
    "### 1. Data Manipulation with Pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {\n",
    "    'name': ['John', 'Alice', 'Bob'],\n",
    "    'age': [28, 24, 32],\n",
    "    'salary': [50000, 45000, 70000]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Basic data operations\n",
    "print(df.head())           # View first few rows\n",
    "print(df.describe())       # Statistical summary\n",
    "print(df['age'].mean())    # Calculate mean age\n",
    "\n",
    "# Filter data\n",
    "high_salary = df[df['salary'] > 50000]\n",
    "\n",
    "# Group by operations\n",
    "avg_salary_by_age = df.groupby('age')['salary'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Numerical Computing with NumPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Create arrays\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Array operations\n",
    "print(arr.mean())          # Calculate mean\n",
    "print(arr.std())           # Calculate standard deviation\n",
    "print(matrix.shape)        # Get dimensions\n",
    "\n",
    "# Mathematical operations\n",
    "squared = np.square(arr)   # Square each element\n",
    "sqrt = np.sqrt(arr)        # Square root of each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Data Visualization with Matplotlib and Seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Basic line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, label='Sine Wave')\n",
    "plt.title('Simple Line Plot')\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Seaborn visualization\n",
    "sns.set_style(\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. Machine Learning with Scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create sample dataset\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 5. Deep Learning with TensorFlow/Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a simple neural network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(10,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Generate sample data\n",
    "X = np.random.random((1000, 10))\n",
    "y = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 6. Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create sample data with missing values\n",
    "data = np.array([[1, 2], [np.nan, 3], [7, 6]])\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_clean = imputer.fit_transform(data)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Key Libraries for Data Science:\n",
    "\n",
    "1. **Data Manipulation**:\n",
    "   - pandas: Data analysis and manipulation\n",
    "   - numpy: Numerical computing\n",
    "\n",
    "2. **Visualization**:\n",
    "   - matplotlib: Basic plotting library\n",
    "   - seaborn: Statistical data visualization\n",
    "   - plotly: Interactive visualizations\n",
    "\n",
    "3. **Machine Learning**:\n",
    "   - scikit-learn: Traditional machine learning\n",
    "   - tensorflow: Deep learning\n",
    "   - keras: High-level neural networks API\n",
    "\n",
    "4. **Statistical Analysis**:\n",
    "   - scipy: Scientific computing\n",
    "   - statsmodels: Statistical models\n",
    "\n",
    "Remember to:\n",
    "- Always explore and clean your data first\n",
    "- Choose appropriate visualization methods\n",
    "- Use proper train-test splits\n",
    "- Validate your models\n",
    "- Document your analysis\n",
    "- Use version control for your code\n",
    "\n",
    "These examples demonstrate basic usage of Python's data science libraries. Each library has many more features and capabilities for specific use cases.\n",
    "\n",
    "Similar code found with 1 license type"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
